{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Flowchart-Detection model\n",
        "I have confirmed that it works with Python 3.11.12."
      ],
      "metadata": {
        "id": "yFrJNKPmAA0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount to g-drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HMgyG9SvAL37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYJwjOm4kNUF"
      },
      "source": [
        "## 1. prepare code and dataaset\n",
        "### 1.1 git clone damo-yolo model\n",
        "- git clone damo-yolo model\n",
        "```bash\n",
        "git clone https://github.com/tinyvision/DAMO-YOLO.git\n",
        "```\n",
        "\n",
        "### 1.2  locate in G-drive\n",
        "- in this notebook, I located it in /content/drive/MyDrive/programs/flow-chart-detection/\n",
        "\n",
        "### 1.3 prepare dataset\n",
        "- Prepare your own dataset in coco dataset format.  \n",
        "The following directory structure is assumed in this notebook.\n",
        "```\n",
        "/content/drive/MyDrive/programs/flow-chart-detection\n",
        "├── ckpt\n",
        "│   ├── damoyolo_tinynasL20_T_436.pth\n",
        "│   └── ...\n",
        "├── damo-yolo\n",
        "│   ├── assets\n",
        "│   ├── configs\n",
        "│   │   ├── damoyolo_tinynasL20_T.py\n",
        "│   │   ├── ...\n",
        "├── ...\n",
        "├── data_coco_format_start_end_train\n",
        "│   ├── annotations\n",
        "│   │   └── instances_custom.json\n",
        "│   └── images\n",
        "│       ├── flowchart-example001.webp\n",
        "│       ├── ...\n",
        "├── data_coco_format_start_end_test\n",
        "│   ├── annotations\n",
        "│   │   └── instances_custom.json\n",
        "│   └── images\n",
        "│       ├── flowchart-example002.webp\n",
        "│       ├── ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hb78-7wiww6t"
      },
      "outputs": [],
      "source": [
        "# install related libraries\n",
        "!pip install cairosvg==2.8.2\n",
        "!apt install tree\n",
        "!pip install xmltodict==0.14.2\n",
        "!pip install albumentations==2.0.6\n",
        "!pip install ultralytics==8.3.137\n",
        "!pip install cairosvg==2.8.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Change the information in the config file\n",
        "Follow the instructions on the following site to change the config file of the damo-yolo model.\n",
        "https://github.com/tinyvision/DAMO-YOLO/blob/master/assets/CustomDatasetTutorial.md\n",
        "\n",
        "### 2.1 Convert the custom dataset to coco format\n",
        "Convert your flowchart dataset to coco data format as follows\n",
        "```\n",
        "{\n",
        "  \"categories\":\n",
        "  [{\n",
        "      \"supercategory\": \"text\",\n",
        "      \"id\": 1,\n",
        "      \"name\": \"text\"\n",
        "  },\n",
        "  {\n",
        "      \"supercategory\": \"arrow\",\n",
        "      \"id\": 2,\n",
        "      \"name\": \"arrow\"\n",
        "  },\n",
        "  ...\n",
        "  ],\n",
        " \"images\":\n",
        "  [{\n",
        "      \"file_name\": \"flowchart-example001.webp\",        \n",
        "      \"height\": 499,\n",
        "      \"width\": 731,\n",
        "      \"id\": 1\n",
        "  },\n",
        "  ...\n",
        "  ],\n",
        " \"annotations\":\n",
        "  [{\n",
        "      \"image_id\": 1,\n",
        "      \"category_id\": 3,\n",
        "      \"segmentation\": [],\n",
        "      \"area\": 5047,\n",
        "      \"iscrowd\": 0,\n",
        "      \"bbox\": [4,1,103,49],\n",
        "      \"id\": 1\n",
        "  },\n",
        "  ...\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BzE2-KL0CIGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Create symbolic linds"
      ],
      "metadata": {
        "id": "fboKwBYrqkyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ex)\n",
        "!ln -s /content/drive/MyDrive/programs/flow-chart-detection/data_coco_format_start_end_test /content/drive/MyDrive/programs/flow-chart-detection/damo-yolo/datasets/custom_coco_test\n",
        "!ln -s /content/drive/MyDrive/programs/flow-chart-detection/data_coco_format_start_end_train /content/drive/MyDrive/programs/flow-chart-detection/damo-yolo/datasets/custom_coco_train"
      ],
      "metadata": {
        "id": "qNXADdT5qicV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Add the custom dataset into DAMO-YOLO\n",
        "Add the custom dataset into `damo/config/paths_catalog.py`. Note, the added dataset should contain coco in their names to declare the dataset format, e.g., here we use `custom_test_coco` and `custom_train_coco`.\n",
        "\n",
        "```\n",
        "'custom_train_coco': {\n",
        "    'img_dir': 'custom_coco_train/images',\n",
        "    'ann_file': 'custom_coco_train/annotations/instances_custom.json'\n",
        "},\n",
        "'custom_test_coco': {\n",
        "    'img_dir': 'custom_coco_test/images',\n",
        "    'ann_file': 'custom_coco_test/annotations/instances_custom.json'\n",
        "},\n",
        "```"
      ],
      "metadata": {
        "id": "ji1rePBxq8Ud"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wvVz-YIQfSMS"
      },
      "outputs": [],
      "source": [
        "# set path to dataaset\n",
        "PATH_TO_FCDetection = '/content/drive/MyDrive/programs/flow-chart-detection'\n",
        "# check dataset path\n",
        "!tree /content/drive/MyDrive/programs/flow-chart-detection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 modify the config file\n",
        "\n",
        "In this notebook, we finetune on DAMO-YOLO-Tiny like official tutorial.\n",
        "- Download the DAMO-YOLO-Tiny torch model from Model Zoo\n",
        "https://github.com/tinyvision/DAMO-YOLO#Model-Zoo\n",
        "- Add the following pretrained model path into `damoyolo_tinynasL20_T.py`.\n",
        "```\n",
        "self.train.finetune_path='path/to/damoyolo_tinynasL20_T.pth'\n",
        "```\n",
        "\n",
        "Modify the custom dataset in config file. Change `coco_2017_train` and `coco_2017_test` in `damoyolo_tinynasL20_T.py` to `custom_train_coco` and `custom_test_coco` respectively around line 33.\n",
        "\n",
        "Modify the category number in config file. Change `'num_classes': 80` `in damoyolo_tinynasL20_T.py` to `'num_classes': 9` around line64. Because in our flow-chart-detection, there is 9 categories, so we set `num_classes` to 9.\n",
        "\n",
        "Modify the list of class names around line 77 like below.\n",
        "```\n",
        "self.dataset.class_names = ['text', 'arrow', 'terminator', 'data', 'process', 'decision', 'connection', 'arrow_start', 'arrow_end']\n",
        "```"
      ],
      "metadata": {
        "id": "m7OTxMkwsU9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-byBZG-mAJay"
      },
      "outputs": [],
      "source": [
        "# install libraries\n",
        "from PIL import Image\n",
        "import cairosvg\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-5FQ6Dcz0uq"
      },
      "source": [
        "# 3. Model building and learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vt7Q63KVyddP"
      },
      "outputs": [],
      "source": [
        "# import torch, else\n",
        "import xml.etree.ElementTree as ET\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.detection import fcos_resnet50_fpn\n",
        "from torchvision.models.detection.fcos import FCOSHead\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import xmltodict\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvMlEh2HwlQb"
      },
      "outputs": [],
      "source": [
        "# install libraries for damo-yolo\n",
        "%cd /content/drive/MyDrive/programs/flow-chart-detection/damo-yolo\n",
        "!pip install -r requirements.txt\n",
        "import os\n",
        "os.environ['PYTHONPATH'] = f\"{os.getcwd()}:{os.environ.get('PYTHONPATH', '')}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih1qNr__xP6T"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo')\n",
        "print(\"sys.path \", sys.path)\n",
        "!export PYTHONPATH=\"$PYTHONPATH:/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo\"\n",
        "!echo $PYTHONPATH\n",
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fr9Me7fsn-O-"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TOG-PUWjZ1Bo"
      },
      "outputs": [],
      "source": [
        "# do fine-tuning. for detail, see damo-yolo official site.\n",
        "# ex)\n",
        "!torchrun --nproc_per_node=1 tools/train.py -f configs/damoyolo_tinynasL20_T.py --local_rank 0 --tea_ckpt /content/drive/MyDrive/programs/flow-chart-detection/ckpt/damoyolo_tinynasL20_T_436.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Visualize training results"
      ],
      "metadata": {
        "id": "s5HCnHlkBHwq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILCEGi7_drEk"
      },
      "outputs": [],
      "source": [
        "# visualize results\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# read files. change this PATH to yours.\n",
        "file_path = '/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo/workdirs/damoyolo_tinynasL20_T/2025-04-23-1819'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# get AP, AR\n",
        "epochs = []\n",
        "ap_values = []\n",
        "ar_values = []\n",
        "current_epoch = None  # initialize current_epoch\n",
        "\n",
        "for line in lines:\n",
        "    # get epoch info\n",
        "    epoch_match = re.search(r'epoch: (\\d+)/', line)\n",
        "    if epoch_match:\n",
        "        current_epoch = int(epoch_match.group(1))\n",
        "\n",
        "    # confirm current_epoch is defined or not\n",
        "    if current_epoch is not None:\n",
        "        # get AP\n",
        "        ap_match = re.search(r'Average Precision\\s+\\(AP\\)\\s+@\\[\\s*IoU=0\\.50:0\\.95.*=\\s+([\\d\\.]+)', line)\n",
        "        if ap_match:\n",
        "            ap_values.append(float(ap_match.group(1)))\n",
        "            epochs.append(current_epoch)\n",
        "\n",
        "        # get AR\n",
        "        ar_match = re.search(r'Average Recall\\s+\\(AR\\)\\s+@\\[\\s*IoU=0\\.50:0\\.95.*=\\s+([\\d\\.]+)', line)\n",
        "        if ar_match:\n",
        "            ar_values.append(float(ar_match.group(1)))\n",
        "\n",
        "# debug\n",
        "print(f\"Number of epochs: {len(epochs)}\")\n",
        "print(f\"Number of AP values: {len(ap_values)}\")\n",
        "print(f\"Number of AR values: {len(ar_values)}\")\n",
        "\n",
        "# Adjustment for inconsistent data counts\n",
        "min_length = min(len(epochs), len(ap_values), len(ar_values))\n",
        "epochs = epochs[:min_length]\n",
        "ap_values = ap_values[:min_length]\n",
        "ar_values = ar_values[:min_length]\n",
        "\n",
        "# make graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, ap_values, label='Average Precision (AP)', marker='o')\n",
        "plt.plot(epochs, ar_values, label='Average Recall (AR)', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.title('AP and AR over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. test and get json file"
      ],
      "metadata": {
        "id": "FZ-cVEt743sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test for your dataset\n",
        "!torchrun --nproc_per_node=1 tools/eval.py \\\n",
        "  -f configs/damoyolo_tinynasL20_T_eval.py \\\n",
        "  --ckpt /content/drive/MyDrive/programs/flow-chart-detection/damo-yolo/workdirs/damoyolo_tinynasL20_T/epoch_3000_ckpt.pth \\\n",
        "  --fuse"
      ],
      "metadata": {
        "id": "cSvWgSjHH870"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert json data including all images to each image json file\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import os\n",
        "\n",
        "# Input file and output directory\n",
        "input_file = os.path.join(PATH_TO_FCDetection, 'damo-yolo/results/custom_eval/inference/custom_test_coco/bbox.json')\n",
        "output_dir = os.path.join(PATH_TO_FCDetection, 'damo-yolo/results/each_images/')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load bbox-2.json\n",
        "with open(input_file, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Group annotations by image_id\n",
        "grouped = defaultdict(list)\n",
        "for i, ann in enumerate(data):\n",
        "    grouped[ann['image_id']].append({\n",
        "        \"id\": i + 1,\n",
        "        \"image_id\": ann['image_id'],\n",
        "        \"category_id\": ann['category_id'],\n",
        "        \"bbox\": [round(x, 2) for x in ann['bbox']],\n",
        "        \"score\": round(ann['score'], 3),\n",
        "        \"area\": round(ann['bbox'][2] * ann['bbox'][3], 2),\n",
        "        \"segmentation\": [],\n",
        "        \"iscrowd\": 0\n",
        "    })\n",
        "\n",
        "# Dummy image info (replace width/height/file_name with actual values if available)\n",
        "# Here we assume all images are 1920x1080 and named as \"image_<id>.png\"\n",
        "for image_id, annotations in grouped.items():\n",
        "    image_info = {\n",
        "        \"id\": image_id,\n",
        "        \"file_name\": f\"image_{image_id}.png\",\n",
        "        \"width\": 1920,\n",
        "        \"height\": 1080\n",
        "    }\n",
        "    output_data = {\n",
        "        \"images\": [image_info],\n",
        "        \"annotations\": annotations\n",
        "    }\n",
        "\n",
        "    # Save as individual JSON file per image\n",
        "    output_path = os.path.join(output_dir, f\"image_{image_id}.json\")\n",
        "    with open(output_path, 'w') as out_f:\n",
        "        json.dump(output_data, out_f, indent=2)\n"
      ],
      "metadata": {
        "id": "T-iyWK-W6I6d"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}