{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKpir9PwNM-H"
      },
      "source": [
        "# git管理 TODO（現在使ってない）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhhx5nacNQI5"
      },
      "outputs": [],
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYJwjOm4kNUF"
      },
      "source": [
        "# Flowchart-Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Z1CN1zy-hTeX"
      },
      "outputs": [],
      "source": [
        "!apt-cache search python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Y8cC2owfjnun"
      },
      "outputs": [],
      "source": [
        "!pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hb78-7wiww6t"
      },
      "outputs": [],
      "source": [
        "# 関連ライブラリのインストール\n",
        "!pip install cairosvg\n",
        "!apt install tree\n",
        "!pip install xmltodict\n",
        "!pip install albumentations\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-yPMwsFkP5A",
        "outputId": "54988619-8ef5-412c-aff5-fec4a457511c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "93eFe1qek89b"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gbgPB23tTBd_",
        "outputId": "0b6bb859-900e-49dc-f872-ace1ce03e8ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# g-driveのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE2HWoBtEeDq",
        "outputId": "13b5b45e-dcd1-4360-8244-f7cd9333bb8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ckpt  data  data_yolo  images  output  runs_l  runs_n\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/programs/flow-chart-detection/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wvVz-YIQfSMS"
      },
      "outputs": [],
      "source": [
        "# datasetへのpathを設定\n",
        "PATH_TO_FCDetection = '/content/drive/MyDrive/programs/flow-chart-detection'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_YzY26Zwj5xB"
      },
      "outputs": [],
      "source": [
        "!tree /content/drive/MyDrive/programs/flow-chart-detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3nzpYyWouqW"
      },
      "source": [
        "# 画像の読み込みと中身確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-byBZG-mAJay"
      },
      "outputs": [],
      "source": [
        "# ライブラリのインストール\n",
        "from PIL import Image\n",
        "import cairosvg\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "5hIBOtLQAOWG"
      },
      "outputs": [],
      "source": [
        "#画像の読み込みと表示\n",
        "files = glob.glob(os.path.join(PATH_TO_FCDetection, 'data', '*'))\n",
        "print(f\"files: {files}\")\n",
        "for path1 in files:\n",
        "  if path1.rsplit('.', 1)[1] == 'xml' or path1.rsplit('.', 1)[1] == 'txt':\n",
        "    continue\n",
        "  if path1.rsplit('.', 1)[1] == 'svg':\n",
        "    img = cairosvg.svg2png(url=path1)\n",
        "    img = Image.open(BytesIO(img))\n",
        "  else:\n",
        "    img = Image.open(path1).convert('RGB')\n",
        "  print(\"type(img), \", type(img))\n",
        "  print(\"img.size, \", img.size)\n",
        "  # img = cv2.imread(path1)\n",
        "  display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVGcRwQSgb4G"
      },
      "source": [
        "## アノテーションの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YXO-OhlEgh14"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "for path1 in files:\n",
        "  if path1.rsplit('.', 1)[1] != 'xml':\n",
        "    continue\n",
        "  tree = ET.parse(path1)\n",
        "  root = tree.getroot()\n",
        "  for child in root:\n",
        "    print(child.tag, child.attrib)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W2SHyUXnjhN"
      },
      "source": [
        "## 画像にアノテーションを描画する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XzIz73dhgdo"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageDraw\n",
        "import xmltodict\n",
        "# xmlのみ収集\n",
        "xml_files = []\n",
        "files = glob.glob(os.path.join(PATH_TO_FCDetection, 'data', '*'))\n",
        "for path1 in files:\n",
        "  if path1.rsplit('.', 1)[1] == 'xml':\n",
        "    xml_files.append(path1)\n",
        "print('xml_files', xml_files)\n",
        "\n",
        "# xmlファイルから対応する画像ファイルを読み込む\n",
        "for xml_path1 in xml_files:\n",
        "  # get image path... png, jpg, jpeg, ...etc\n",
        "  # img_path_base = xml_path1.rsplit('.', 1)[0]\n",
        "  # files = glob.glob(os.path.join(PATH_TO_FCDetection, 'data', img_path_base + '.*'))\n",
        "  # img_file_name = None\n",
        "  # for path1 in files:\n",
        "  #   if path1.rsplit('.', 1)[1] != 'xml':\n",
        "  #     img_file_name = path1\n",
        "\n",
        "  with open(xml_path1, 'r') as f:\n",
        "      xml_string = f.read()\n",
        "  xml_dict = xmltodict.parse(xml_string)\n",
        "\n",
        "  colors = {'terminator':\"red\",\n",
        "            'process':\"green\",\n",
        "            'decision':\"#808080\",\n",
        "            'arrow':\"#FFA500\",\n",
        "            'text':\"blue\",\n",
        "            'start_point':\"#800080\",\n",
        "            'data':\"grey\",\n",
        "            'connection':\"black\",\n",
        "            'end_point':\"yellow\"}\n",
        "\n",
        "  anno_dict = xml_dict['annotation']\n",
        "  # open image\n",
        "  filename = anno_dict['filename']\n",
        "  file_path = os.path.join(PATH_TO_FCDetection, 'data', filename)\n",
        "  print(\"file_path, \", file_path)\n",
        "  # if filename.rsplit('.', 1)[1] == 'gif':\n",
        "  img = Image.open(file_path).convert('RGB')\n",
        "  # else:\n",
        "  #   img = Image.open(file_path)\n",
        "  print(\"type(img), \", type(img))\n",
        "  print(\"img.size, \", img.size)\n",
        "  # ImageDrawオブジェクトの作成\n",
        "  draw = ImageDraw.Draw(img)\n",
        "\n",
        "  for key, value in anno_dict.items():\n",
        "    if key == 'object':\n",
        "      for object1 in value:\n",
        "        print(\"object1, \", object1)\n",
        "        xmin = int(object1['bndbox']['xmin'])\n",
        "        ymin = int(object1['bndbox']['ymin'])\n",
        "        xmax = int(object1['bndbox']['xmax'])\n",
        "        ymax = int(object1['bndbox']['ymax'])\n",
        "\n",
        "        # 矩形の描画\n",
        "        # (x1, y1)は左上の座標、(x2, y2)は右下の座標\n",
        "        print(\"\")\n",
        "        draw.rectangle((xmin, ymin, xmax, ymax), outline=colors[object1['name']],\n",
        "                       width=3) # fill=colors[object1['name']],\n",
        "\n",
        "  # 画像の保存\n",
        "  # img.save('rectangle.png')\n",
        "  display(img)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-5FQ6Dcz0uq"
      },
      "source": [
        "# モデルの構築と学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxh_SptQyZrT"
      },
      "source": [
        "## importするtorch関係ライブラリ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vt7Q63KVyddP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcae2df8-a60e-415e-d954-347316c8ee0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.detection import fcos_resnet50_fpn\n",
        "from torchvision.models.detection.fcos import FCOSHead\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import xmltodict\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFLAkQshymJf"
      },
      "source": [
        "## annotationの前処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Slj2L-khyr0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2020dc0-7aa1-42a5-9b13-a85594bdca43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted flowchart-example001.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example001.txt\n",
            "Converted flowchart-example002.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example002.txt\n",
            "Converted flowchart-example003.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example003.txt\n",
            "Converted flowchart-example004.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example004.txt\n",
            "Converted flowchart-example007.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example007.txt\n",
            "Converted flowchart-example008.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example008.txt\n",
            "Converted flowchart-example009.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example009.txt\n",
            "Converted flowchart-example013.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example013.txt\n",
            "Converted flowchart-example014.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example014.txt\n",
            "Converted flowchart-example015.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example015.txt\n",
            "Converted flowchart-example016.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example016.txt\n",
            "Converted flowchart-example017.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example017.txt\n",
            "Converted flowchart-example019.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example019.txt\n",
            "Converted flowchart-example020.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example020.txt\n",
            "Converted flowchart-example021.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example021.txt\n",
            "Converted flowchart-example025.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example025.txt\n",
            "Converted flowchart-example029.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example029.txt\n",
            "Converted flowchart-example027.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example027.txt\n",
            "Converted flowchart-example030.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example030.txt\n",
            "Converted flowchart-example022.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example022.txt\n",
            "Converted flowchart-example006.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example006.txt\n",
            "Converted flowchart-example012.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example012.txt\n",
            "Converted flowchart-example032.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example032.txt\n",
            "Converted flowchart-example033.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example033.txt\n",
            "Converted flowchart-example034.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example034.txt\n",
            "Converted flowchart-example035.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example035.txt\n",
            "Converted flowchart-example040.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example040.txt\n",
            "Converted flowchart-example039.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example039.txt\n",
            "Converted flowchart-example038.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example038.txt\n",
            "Converted flowchart-example037.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example037.txt\n",
            "Converted flowchart-example036.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example036.txt\n",
            "Converted flowchart-example041.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example041.txt\n",
            "Converted flowchart-example042.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example042.txt\n",
            "Converted flowchart-example043.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example043.txt\n",
            "Converted flowchart-example044.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example044.txt\n",
            "Converted flowchart-example045.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example045.txt\n",
            "Converted flowchart-example046.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example046.txt\n",
            "Converted flowchart-example047.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example047.txt\n",
            "Converted flowchart-example048.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example048.txt\n",
            "Converted flowchart-example049.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example049.txt\n",
            "Converted flowchart-example050.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example050.txt\n",
            "Converted flowchart-example051.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example051.txt\n",
            "Converted flowchart-example052.xml to /content/drive/MyDrive/programs/flow-chart-detection/data_yolo/flowchart-example052.txt\n"
          ]
        }
      ],
      "source": [
        "LABELS = {'text':0,\n",
        "          'arrow':1,\n",
        "          'connection':2,\n",
        "          'data':3,\n",
        "          'decision':4,\n",
        "          'process':5,\n",
        "          'terminator':6}\n",
        "\n",
        "\n",
        "def convert_xml_to_yolo(xml_dir, output_dir, image_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    xml_files = [f for f in os.listdir(xml_dir) if f.endswith('.xml')]\n",
        "\n",
        "    for xml_file in xml_files:\n",
        "        # XMLファイルを読み込み\n",
        "        tree = ET.parse(os.path.join(xml_dir, xml_file))\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # 画像情報を取得\n",
        "        filename = root.find('filename').text\n",
        "        img_path = os.path.join(image_dir, filename)\n",
        "        img_width = int(root.find('size/width').text)\n",
        "        img_height = int(root.find('size/height').text)\n",
        "\n",
        "        # 出力先ファイル名\n",
        "        output_txt_path = os.path.join(output_dir, os.path.splitext(filename)[0] + '.txt')\n",
        "\n",
        "        # バウンディングボックスを変換\n",
        "        with open(output_txt_path, 'w') as f:\n",
        "            for obj in root.findall('object'):\n",
        "                class_name = obj.find('name').text\n",
        "                if class_name not in LABELS:\n",
        "                    continue  # 定義されていないクラスはスキップ\n",
        "                class_id = LABELS[class_name]\n",
        "                bndbox = obj.find('bndbox')\n",
        "                xmin = int(bndbox.find('xmin').text)\n",
        "                ymin = int(bndbox.find('ymin').text)\n",
        "                xmax = int(bndbox.find('xmax').text)\n",
        "                ymax = int(bndbox.find('ymax').text)\n",
        "\n",
        "                # YOLO形式に変換\n",
        "                x_center = (xmin + xmax) / 2 / img_width\n",
        "                y_center = (ymin + ymax) / 2 / img_height\n",
        "                width = (xmax - xmin) / img_width\n",
        "                height = (ymax - ymin) / img_height\n",
        "\n",
        "                # 書き込み\n",
        "                f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "\n",
        "        print(f\"Converted {xml_file} to {output_txt_path}\")\n",
        "\n",
        "# パスの設定\n",
        "xml_dir = os.path.join(PATH_TO_FCDetection, 'data')  # XMLファイルのディレクトリ\n",
        "output_dir = os.path.join(PATH_TO_FCDetection, 'data_yolo')  # YOLO形式アノテーションの出力先\n",
        "image_dir = os.path.join(PATH_TO_FCDetection, 'data')  # 画像が格納されているディレクトリ\n",
        "\n",
        "# 実行\n",
        "convert_xml_to_yolo(xml_dir, output_dir, image_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU5WGTx2Fdkr",
        "outputId": "4d3beb00-86f7-4bbe-b8fa-97b222bae102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t damo\t   LICENSE  README_cn.md  requirements.txt  setup.py\n",
            "configs  datasets  NOTICE   README.md\t  scripts\t    tools\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwr8iw6fFRQr",
        "outputId": "de3cd5b6-c800-49be-a14b-d8f2372a3627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOX'...\n",
            "Host key verification failed.\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n",
            "drive  sample_data\n",
            "[Errno 2] No such file or directory: 'YOLOX'\n",
            "/content\n",
            "Using pip 24.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Obtaining file:///content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!git clone git@github.com:Megvii-BaseDetection/YOLOX.git\n",
        "!ls\n",
        "%cd YOLOX\n",
        "!pip3 install -v -e .  # or  python3 setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvMlEh2HwlQb"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tinyvision/damo-yolo.git\n",
        "!ls damo-yolo/\n",
        "%cd damo-yolo/\n",
        "!pip install -r requirements.txt\n",
        "import os\n",
        "os.environ['PYTHONPATH'] = f\"{os.getcwd()}:{os.environ.get('PYTHONPATH', '')}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXXTyJRb8Kg1",
        "outputId": "50852c6e-7a07-445b-939f-a8cf96d8acec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t damo\t   LICENSE  README_cn.md  requirements.txt  setup.py\n",
            "configs  datasets  NOTICE   README.md\t  scripts\t    tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN1tPfPPw8hC",
        "outputId": "46820967-dcaf-4f8d-ee1f-561f6793498e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: DAMO-YOLO Demo [-h] [-f CONFIG_FILE] [-p PATH] [--camid CAMID] [--engine ENGINE]\n",
            "                      [--device DEVICE] [--output_dir OUTPUT_DIR] [--conf CONF]\n",
            "                      [--infer_size INFER_SIZE [INFER_SIZE ...]] [--end2end]\n",
            "                      [--save_result SAVE_RESULT]\n",
            "                      input_type\n",
            "\n",
            "positional arguments:\n",
            "  input_type            input type, support [image, video, camera]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  -f CONFIG_FILE, --config_file CONFIG_FILE\n",
            "                        pls input your config file\n",
            "  -p PATH, --path PATH  path to image or video\n",
            "  --camid CAMID         camera id, necessary when input_type is camera\n",
            "  --engine ENGINE       engine for inference\n",
            "  --device DEVICE       device used to inference\n",
            "  --output_dir OUTPUT_DIR\n",
            "                        where to save inference results\n",
            "  --conf CONF           conf of visualization\n",
            "  --infer_size INFER_SIZE [INFER_SIZE ...]\n",
            "                        test img size\n",
            "  --end2end             trt engine with nms\n",
            "  --save_result SAVE_RESULT\n",
            "                        whether save visualization results\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# %cd damo-yolo/\n",
        "os.environ['PYTHONPATH'] = f\"{os.getcwd()}:{os.environ.get('PYTHONPATH', '')}\"\n",
        "!python tools/demo.py --help\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih1qNr__xP6T",
        "outputId": "fe4e7ca8-0dd3-452e-ed0c-98732c8facae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sys.path  ['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/usr/local/lib/python3.10/dist-packages/setuptools/_vendor', '/root/.ipython', '/tmp/tmpid1l89rn', '/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo', '/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo', '/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo', '/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo', '/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo']\n",
            "/env/python\n",
            "assets\t damo\t   LICENSE  README_cn.md  requirements.txt  setup.py\n",
            "configs  datasets  NOTICE   README.md\t  scripts\t    tools\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-49nuzyih\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-49nuzyih\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "\u001b[31mERROR: git+https://github.com/cocodataset/cocoapi.git does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip install cython\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo')\n",
        "print(\"sys.path \", sys.path)\n",
        "# %cd damo-yolo/\n",
        "!export PYTHONPATH=\"$PYTHONPATH:/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo\"\n",
        "!echo $PYTHONPATH\n",
        "!ls\n",
        "!pip install git+https://github.com/cocodataset/cocoapi.git #subdirectory=PythonAPI # for Linux\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../\n",
        "!cp -r damo-yolo /content/drive/MyDrive/programs/flow-chart-detection/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rdt7IjHF5wD",
        "outputId": "27b24530-deee-431b-d576-7dc35c7bada2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/damo-yolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOGxy5HfSTLp",
        "outputId": "45ff114b-87ad-4122-b04c-8f5fcb33f5b7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jjWCuHFrxPu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e17909-5bad-4b0c-f26b-8a22c64ea0a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo\n",
            "/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo\n",
            "assets\t damo\t   demo     NOTICE\t  README.md\t    scripts   tools\n",
            "configs  datasets  LICENSE  README_cn.md  requirements.txt  setup.py\n",
            "/env/python:/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo\n",
            "Inference with torch engine!\n",
            "/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo/tools/demo.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(self.ckpt_path, map_location=self.device)\n",
            "save visualization results at ./demo/dog.jpg\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/programs/flow-chart-detection/damo-yolo\n",
        "import sys\n",
        "!pwd\n",
        "!ls\n",
        "sys.path.append('/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo')\n",
        "# !export PYTHONPATH=\"/env/python\"\n",
        "import os\n",
        "os.environ['PYTHONPATH'] = \"/env/python:/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo\"\n",
        "# os.environ['PYTHONPATH'] = f\"{os.getcwd()}:{os.environ.get('PYTHONPATH', '')}\n",
        "# !export PYTHONPATH=\"$PYTHONPATH:/content/drive/MyDrive/programs/flow-chart-detection/damo-yolo\"\n",
        "# os.environ['PYTHONPATH'] = f\"{os.getcwd()}:{os.environ.get('PYTHONPATH', '')}\n",
        "!echo $PYTHONPATH\n",
        "!python tools/demo.py image -f ./configs/damoyolo_tinynasL25_S.py --engine /content/drive/MyDrive/programs/flow-chart-detection/ckpt/damoyolo_tinynasL25_S_477.pth --conf 0.6 --infer_size 640 640 --device cuda --path ./assets/dog.jpg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUZQchOYK25v"
      },
      "source": [
        "## pascal voc 形式の独自データを coco 形式に変える"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# 入力ディレクトリ（XMLファイルと画像が格納されているディレクトリ）\n",
        "input_dir = \"../data/\"\n",
        "output_dir = \"../data_coco_format\"\n",
        "os.makedirs(os.path.join(output_dir, \"annotations\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, \"images\"), exist_ok=True)\n",
        "\n",
        "# COCO形式のJSONファイル\n",
        "output_json_path = os.path.join(output_dir, \"annotations\", \"instances_custom.json\")\n",
        "\n",
        "# カテゴリの定義\n",
        "\"\"\"\n",
        "text\n",
        "arrow\n",
        "terminator\n",
        "data\n",
        "process\n",
        "decision\n",
        "connection\n",
        "\"\"\"\n",
        "\n",
        "categories = [\n",
        "    {\"id\": 1, \"name\": \"text\", \"supercategory\": \"object\"},\n",
        "    {\"id\": 2, \"name\": \"arrow\", \"supercategory\": \"object\"},\n",
        "    {\"id\": 3, \"name\": \"terminator\", \"supercategory\": \"object\"},\n",
        "    {\"id\": 4, \"name\": \"data\", \"supercategory\": \"object\"},\n",
        "    {\"id\": 5, \"name\": \"process\", \"supercategory\": \"object\"},\n",
        "    {\"id\": 6, \"name\": \"decision\", \"supercategory\": \"object\"},\n",
        "    {\"id\": 7, \"name\": \"connection\", \"supercategory\": \"object\"},\n",
        "    # 必要に応じてカテゴリを追加\n",
        "]\n",
        "\n",
        "category_name_to_id = {category[\"name\"]: category[\"id\"] for category in categories}\n",
        "\n",
        "# COCO JSONの初期化\n",
        "coco_format = {\n",
        "    \"images\": [],\n",
        "    \"annotations\": [],\n",
        "    \"categories\": categories,\n",
        "}\n",
        "\n",
        "# アノテーションIDカウンタ\n",
        "annotation_id = 1\n",
        "\n",
        "# XMLファイルを処理\n",
        "for xml_file in sorted(os.listdir(input_dir)):\n",
        "    if not xml_file.endswith(\".xml\"):\n",
        "        continue\n",
        "\n",
        "    # XMLを解析\n",
        "    tree = ET.parse(os.path.join(input_dir, xml_file))\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # 画像情報\n",
        "    filename = root.find(\"filename\").text\n",
        "    width = int(root.find(\"size/width\").text)\n",
        "    height = int(root.find(\"size/height\").text)\n",
        "    image_id = len(coco_format[\"images\"]) + 1\n",
        "\n",
        "    # COCO形式の画像情報を追加\n",
        "    coco_format[\"images\"].append({\n",
        "        \"id\": image_id,\n",
        "        \"file_name\": filename,\n",
        "        \"width\": width,\n",
        "        \"height\": height,\n",
        "    })\n",
        "\n",
        "    # 画像を出力フォルダにコピー（オプション）\n",
        "    image_path = os.path.join(input_dir, filename)\n",
        "    if os.path.exists(image_path):\n",
        "        os.system(f\"cp {image_path} {os.path.join(output_dir, 'images', filename)}\")\n",
        "\n",
        "    # アノテーション情報を追加\n",
        "    for obj in root.findall(\"object\"):\n",
        "        category_name = obj.find(\"name\").text\n",
        "        if category_name not in category_name_to_id:\n",
        "            continue  # 定義されていないカテゴリはスキップ\n",
        "\n",
        "        category_id = category_name_to_id[category_name]\n",
        "        bbox_xml = obj.find(\"bndbox\")\n",
        "        xmin = int(bbox_xml.find(\"xmin\").text)\n",
        "        ymin = int(bbox_xml.find(\"ymin\").text)\n",
        "        xmax = int(bbox_xml.find(\"xmax\").text)\n",
        "        ymax = int(bbox_xml.find(\"ymax\").text)\n",
        "\n",
        "        # COCO形式のbboxは[x, y, width, height]\n",
        "        bbox = [xmin, ymin, xmax - xmin, ymax - ymin]\n",
        "        area = bbox[2] * bbox[3]  # 面積\n",
        "\n",
        "        coco_format[\"annotations\"].append({\n",
        "            \"id\": annotation_id,\n",
        "            \"image_id\": image_id,\n",
        "            \"category_id\": category_id,\n",
        "            \"bbox\": bbox,\n",
        "            \"area\": area,\n",
        "            \"segmentation\": [],  # セグメンテーションは省略\n",
        "            \"iscrowd\": 0,\n",
        "        })\n",
        "        annotation_id += 1\n",
        "\n",
        "# JSONファイルとして保存\n",
        "with open(output_json_path, \"w\") as json_file:\n",
        "    json.dump(coco_format, json_file, indent=4)\n",
        "\n",
        "print(f\"COCO形式のJSONファイルが生成されました: {output_json_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zJIYJ36SMOV",
        "outputId": "851175c0-be0d-427d-c9d5-c3c835b69835"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COCO形式のJSONファイルが生成されました: ../data_coco_format/annotations/instances_custom.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s ../data_coco_format /content/drive/MyDrive/programs/flow-chart-detection/damo-yolo/datasets/custom_coco"
      ],
      "metadata": {
        "id": "BuBvizr3Wc2p"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py -f configs/damoyolo_tinynasL25_S.py -d 1 -b 8 --fp16 -o --cache\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wWVylHdZPp5",
        "outputId": "b8e66654-83c9-481e-ae8f-a60829ee9b45"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: Damo-Yolo train parser [-h] [-f CONFIG_FILE] [--local_rank LOCAL_RANK]\n",
            "                              [--tea_config TEA_CONFIG] [--tea_ckpt TEA_CKPT]\n",
            "                              ...\n",
            "Damo-Yolo train parser: error: unrecognized arguments: -d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tmp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# end"
      ],
      "metadata": {
        "id": "1CDdipOeWZnH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbTOcgLLKV9F"
      },
      "outputs": [],
      "source": [
        "# COCO datasetで事前学習\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "# model = YOLO(\"yolo11n.pt\")\n",
        "model = YOLO(\"yolo11l.pt\")\n",
        "\n",
        "# Train the model\n",
        "train_results = model.train(\n",
        "    data=\"coco8.yaml\",  # path to dataset YAML\n",
        "    epochs=100,  # number of training epochs\n",
        "    imgsz=640,  # training image size\n",
        "    device=\"cpu\",  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n",
        ")\n",
        "\n",
        "# Evaluate model performance on the validation set\n",
        "metrics = model.val()\n",
        "\n",
        "# Perform object detection on an image\n",
        "results = model(os.path.join(PATH_TO_FCDetection, 'images/200730_am01.jpg'))\n",
        "results[0].show()\n",
        "\n",
        "# Export the model to ONNX format\n",
        "path = model.export(format=\"onnx\")  # return path to exported model\n",
        "# path = model.export(format=\"pth\")  # return path to exported model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FUBq5ILs_1x"
      },
      "source": [
        "## yolo datasetに向けた事前準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "collapsed": true,
        "id": "BJdeX9iMpOh_",
        "outputId": "db660145-a3b1-43d8-fc0d-d3b091f21c5c"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9ad2d153de5b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_FCDetection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_yolo/images/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                     \u001b[0;31m# macOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                             \u001b[0m_fastcopy_fcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_COPYFILE_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# dataディレクトリから画像を data_yolo へコピー\n",
        "import shutil\n",
        "\n",
        "img_files = glob.glob(os.path.join(PATH_TO_FCDetection, 'data', '*'))\n",
        "for path1 in img_files:\n",
        "  if path1.rsplit('.', 1)[1] == 'xml' or path1.rsplit('.', 1)[1] == 'txt':\n",
        "    continue\n",
        "    print(path1)\n",
        "  shutil.copy(path1, os.path.join(PATH_TO_FCDetection, 'data_yolo/images/train'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug5U0K5xvIBJ"
      },
      "outputs": [],
      "source": [
        "# yoloの学習\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(os.path.join(PATH_TO_FCDetection, 'runs_l/train/weights/best.pt'))\n",
        "model.train(\n",
        "    data=os.path.join(PATH_TO_FCDetection, 'data_yolo/yolov11_l_241212.yaml'),  # 絶対パス\n",
        "    epochs=100,\n",
        "    imgsz=640\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX4qxE6qxS15",
        "outputId": "f2124796-7fb8-43a0-a39f-7206b0001483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 28\n",
            "drwx------ 2 root root 4096 Nov 29 01:18 ckpt\n",
            "drwx------ 2 root root 4096 Nov 26 19:54 data\n",
            "drwx------ 4 root root 4096 Dec 12 04:29 data_yolo\n",
            "drwx------ 2 root root 4096 Dec 11 03:22 images\n",
            "drwx------ 2 root root 4096 Nov 26 22:51 output\n",
            "drwx------ 4 root root 4096 Dec 11 04:18 runs_l\n",
            "drwx------ 6 root root 4096 Dec 11 04:01 runs_n\n",
            "ls: cannot access 'runs/detect/train/weights': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# 保存モデルの確認\n",
        "!ls -la /content/drive/MyDrive/programs/flow-chart-detection/\n",
        "!ls -la runs/detect/train/weights\n",
        "# !mv yolo11n.pt yolo11_l_2412120234.pt\n",
        "# !cp runs/detect/train/weights/best.pt /content/drive/MyDrive/programs/flow-chart-detection/runs_l/train/weights/yolo11_l_24120239.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgyyiiDa8em5"
      },
      "outputs": [],
      "source": [
        "# 保存したパラメータによる推論\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import glob\n",
        "# Load a model\n",
        "# model = YOLO(\"yolo11n.pt\")\n",
        "model = YOLO(os.path.join(PATH_TO_FCDetection, 'runs_l/train/weights/yolo11_l_24120239.pt'))\n",
        "# model = YOLO(\"yolo11l.pt\n",
        "\n",
        "# Train the model\n",
        "# train_results = model.train(\n",
        "#     data=\"coco8.yaml\",  # path to dataset YAML\n",
        "#     epochs=100,  # number of training epochs\n",
        "#     imgsz=640,  # training image size\n",
        "#     device=\"cpu\",  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n",
        "# )\n",
        "\n",
        "# Evaluate model performance on the validation set\n",
        "# metrics = model.val()\n",
        "\n",
        "# results = model(os.path.join(PATH_TO_FCDetection, 'images/200730_am01.jpg'))\n",
        "# results = model(os.path.join(PATH_TO_FCDetection, 'images/animals.jpeg'))\n",
        "img_paths = glob.glob(os.path.join(PATH_TO_FCDetection, 'data_yolo/images/val', '*'))\n",
        "for img_path in img_paths:\n",
        "  results = model(img_path)\n",
        "  results[0].show()\n",
        "  print(\"type(results[0]) \", type(results[0]))\n",
        "# results = model.predict(os.path.join(PATH_TO_FCDetection, 'data_yolo/images/animals.jpeg'))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtBG7mAvKfUP"
      },
      "outputs": [],
      "source": [
        "# 保存したぱらめーたによる推論\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(os.path.join(PATH_TO_FCDetection, 'runs_l/train/weights/best.pt'))\n",
        "\n",
        "results = model(os.path.join(PATH_TO_FCDetection, 'images/200730_am01.jpg'))\n",
        "# results[0].show()\n",
        "print(\"type(results[0]) \", type(results[0]))\n",
        "print(\"len(results) \", len(results))\n",
        "for box in results[0].boxes:\n",
        "    print(\"type(box) \", type(box))\n",
        "    print(\"type(box.xyxy) \", type(box.xyxy))\n",
        "    x1, y1, x2, y2 = box.xyxy[0].tolist()  # バウンディングボックスの座標 (左上と右下)\n",
        "    confidence = box.conf[0].item()        # 信頼度\n",
        "    cls = int(box.cls[0].item())          # クラスID\n",
        "    print(f\"Class: {cls}, Confidence: {confidence:.2f}, BBox: [{x1:.2f}, {y1:.2f}, {x2:.2f}, {y2:.2f}]\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}